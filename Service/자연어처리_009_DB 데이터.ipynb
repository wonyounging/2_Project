{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB 접속 정보 불러오기\n",
    "with open('c:/2nd_project/Service/DB_config.txt') as f:\n",
    "    conf = f.readlines()\n",
    "    DB_HOST = conf[0].replace('\\n','')\n",
    "    DB_USER = conf[1].replace('\\n','')\n",
    "    DB_PASSWORD = conf[2].replace('\\n','')\n",
    "    DB_NAME = conf[3].replace('\\n','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import pymysql.cursors\n",
    "import logging\n",
    "\n",
    "class Database:\n",
    "    def __init__(self, host, user, password, db_name, charset='utf8'):\n",
    "        self.host = host\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.db_name = db_name\n",
    "        self.charset = charset\n",
    "        self.conn = None\n",
    "\n",
    "    def connect(self):\n",
    "        if self.conn != None:\n",
    "            return\n",
    "        self.conn = pymysql.connect(\n",
    "            host=self.host,\n",
    "            user=self.user,\n",
    "            password=self.password,\n",
    "            db=self.db_name,\n",
    "            charset=self.charset\n",
    "        )\n",
    "\n",
    "    def close(self):\n",
    "        if self.conn is None:\n",
    "            return\n",
    "        if not self.conn.open:\n",
    "            self.conn = None\n",
    "            return\n",
    "        self.conn.close()\n",
    "        self.conn = None\n",
    "\n",
    "    def execute(self, sql):\n",
    "        last_row_id = -1\n",
    "        try:\n",
    "            with self.conn.cursor() as cursor:\n",
    "                cursor.execute(sql)\n",
    "            self.conn.commit()\n",
    "            last_row_id = cursor.lastrowid\n",
    "        except Exception as ex:\n",
    "            logging.error(ex)\n",
    "        finally:\n",
    "            return last_row_id\n",
    "        \n",
    "    def select_one(self, sql):\n",
    "        result = None\n",
    "        try:\n",
    "            with self.conn.cursor(pymysql.cursors.DictCursor) as cursor:\n",
    "                cursor.execute(sql)\n",
    "                result = cursor.fetchone()\n",
    "        except Exception as ex:\n",
    "            logging.error(ex)\n",
    "        finally:\n",
    "            return result\n",
    "\n",
    "    def select_all(self, sql):\n",
    "        result = None\n",
    "        try:\n",
    "            with self.conn.cursor(pymysql.cursors.DictCursor) as cursor:\n",
    "                cursor.execute(sql)\n",
    "                result = cursor.fetchall()\n",
    "        except Exception as ex:\n",
    "            logging.error(ex)\n",
    "        finally:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "영화명                                                  #살아있다\n",
       "개봉일                                             2020-06-24\n",
       "누적관객수                                              1903992\n",
       "등급                                                15세이상관람가\n",
       "장르                                                     드라마\n",
       "대표국적                                                    한국\n",
       "국적                                                      한국\n",
       "제작사                                      영화사 집,(주)퍼스펙티브픽쳐스\n",
       "배급사                                      롯데컬처웍스(주)롯데엔터테인먼트\n",
       "감독                                                     조일형\n",
       "배우       유아인,박신혜,전배수,고나영,권용채,김경태,김다영,김단비,김라희,김미래,김미래,김윤...\n",
       "줄거리                                                    NaN\n",
       "키워드                                                    NaN\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df = pd.read_excel('c:/2nd_project/Data/movie_data/[KOBIS] 박스오피스_줄거리_감정키워드(2003.01~2023.07).xlsx', engine='openpyxl')\n",
    "# df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert 쿼리 생성\n",
    "def InsertMovie(series):\n",
    "    try: \n",
    "        sql = f'''insert chat_movie(title, opendate, people, grade, genre, repnation, nations, \n",
    "        Production, distributor, director, actors, story, keyword) values (\"{series[0]}\", \"{series[1]}\",\n",
    "        \"{series[2]}\", \"{series[3]}\", \"{series[4]}\", \"{series[5]}\", \"{series[6]}\", \"{series[7]}\", \"{series[8]}\",\n",
    "        \"{series[9]}\", \"{series[10]}\", \"{series[11]}\", \"{series[12]}\")'''\n",
    "\n",
    "        # 엑셀에서 불러온 cell에 데이터가 없는 경우 null로 치환\n",
    "        sql = sql.replace('nan', 'null').replace('None','null')\n",
    "        \n",
    "        db.execute(sql)\n",
    "        \n",
    "    except Exception as ex:\n",
    "        logging.error(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = Database(host=DB_HOST, user=DB_USER, password=DB_PASSWORD, db_name=DB_NAME)\n",
    "# db.connect() \n",
    "\n",
    "# for i in range(len(df)):\n",
    "#     InsertMovie(df.iloc[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 답변 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindAnswer:\n",
    "    def __init__(self, db):\n",
    "        self.db = db\n",
    "        \n",
    "    # 검색 쿼리 생성\n",
    "    def _make_query(self, lst):\n",
    "        self.intent = lst[0]\n",
    "        self.situation = lst[1]\n",
    "        self.emotion = lst[2]\n",
    "        self.story = lst[3]\n",
    "        \n",
    "        sql = 'select * from chat_movie'\n",
    "        if self.intent == \"추천\":\n",
    "            if self.story != \"-\":\n",
    "                sql = sql + f\" where keyword='{self.story}'\"\n",
    "\n",
    "        # 누적관객수 100만명 이상이고 답변이 여러개일 경우 랜덤으로 하나만 뽑기\n",
    "        sql = sql + \" and people>=1000000 order by rand() limit 1\"\n",
    "        return sql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# db = Database(host=DB_HOST, user=DB_USER, password=DB_PASSWORD, db_name=DB_NAME)\n",
    "# db.connect() \n",
    "\n",
    "# # sql = \"select * from chat_movie where keyword='학교' and people>=1000000 order by rand() limit 1\"\n",
    "# # sql = \"select * from chat_movie where story like '%가족%' and people>=1000000 order by rand() limit 1\"\n",
    "# # sql = \"select * from chat_movie where story like '%눈물%' and people>=1000000 order by rand() limit 1\"\n",
    "\n",
    "# db.select_all(sql)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"select * from chat_movie where keyword not like '%슬픔%' and keyword !='null' and people>=5000000 order by rand() limit 1\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = 'select * from chat_movie'\n",
    "lst = ['추천','슬픔','부정','인기']\n",
    "\n",
    "if lst[0] == \"추천\":\n",
    "    if lst[2] == \"긍정\":\n",
    "        sql_q = \" keyword like \"\n",
    "    elif lst[2] == '부정':\n",
    "        sql_q = \" keyword not like \"\n",
    "    else:\n",
    "        sql_q = \" keyword not like \"\n",
    "    \n",
    "    if lst[1] != \"없음\":\n",
    "        sql = sql + \" where\" + sql_q + f\"'%{lst[1]}%'\" +\" and keyword !='null' and\" \n",
    "    else:\n",
    "        sql = sql + \" where\"\n",
    "        \n",
    "    if lst[3] == '최신':\n",
    "        sql = sql + \" people>=1000000 order by opendate DESC limit 1\"\n",
    "    elif lst[3] == '인기':\n",
    "        sql = sql + \" people>=5000000 order by rand() limit 1\"\n",
    "    else:\n",
    "        sql = sql + \" people>=1000000 order by rand() limit 1\"\n",
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"select * from chat_movie WHERE ( and opendate >= '2023-02-18') order by rand() limit 1;\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:(1064, \"You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'and opendate >= '2023-02-18') order by rand() limit 1' at line 1\")\n"
     ]
    }
   ],
   "source": [
    "db = Database(host=DB_HOST, user=DB_USER, password=DB_PASSWORD, db_name=DB_NAME)\n",
    "db.connect() \n",
    "\n",
    "db.select_all(sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Komoran\n",
    "import pickle\n",
    "import jpype\n",
    "\n",
    "class Preprocess :\n",
    "    def __init__(self, word2index_dic='', userdic=None):\n",
    "        # 단어 인덱스 사전 불러오기\n",
    "        if (word2index_dic != ''):\n",
    "            f = open(word2index_dic, 'rb')\n",
    "            self.word_index = pickle.load(f)\n",
    "            f.close()\n",
    "        else:\n",
    "            self.word_index = None\n",
    "            \n",
    "        # 형태소 분석기 초기화\n",
    "        self.komoran = Komoran(userdic=userdic)\n",
    "        \n",
    "        # 제외할 품사\n",
    "        # 참조 : https://docs.komoran.kr/firststep/postypes.html\n",
    "        # 관계언, 기호, 어미, 접미사 제거\n",
    "        self.exclusion_tags = [\n",
    "            'JKS', 'JKC', 'JKG', 'JKO', 'JKB', 'JKV', 'JKQ',\n",
    "            'JX', 'JC',\n",
    "            'SF', 'SP', 'SS', 'SE', 'SO',\n",
    "            'EP', 'EF', 'EC', 'ETN', 'ETM',\n",
    "            'XSN', 'XSV', 'XSA'\n",
    "        ]\n",
    "        \n",
    "    # 형태소 분석기\n",
    "    def pos(self, sentence):\n",
    "        jpype.attachThreadToJVM()\n",
    "        return self.komoran.pos(sentence)\n",
    "        \n",
    "    # 불용어 제거 후, 필요한 품사 정보만 가져오기\n",
    "    def get_keywords(self, pos, without_tag=False):\n",
    "        f = lambda x: x in self.exclusion_tags\n",
    "        word_list = []\n",
    "        for p in pos:\n",
    "            if f(p[1]) is False:\n",
    "                word_list.append(p if without_tag is False else p[0])\n",
    "        return word_list\n",
    "    \n",
    "    # 키워드를 단어 인덱스 시퀀스로 변환\n",
    "    def get_wordidx_sequence(self, keywords):\n",
    "        if self.word_index is None:\n",
    "            return []\n",
    "        \n",
    "        w2i = []\n",
    "        for word in keywords:\n",
    "            try:\n",
    "                w2i.append(self.word_index[word])\n",
    "            except KeyError:\n",
    "                # 해당 단어가 사전에 없는 경우, OOV 처리\n",
    "                w2i.append(self.word_index['OOV'])\n",
    "        return w2i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import preprocessing\n",
    "import numpy as np\n",
    "\n",
    "# 분류 모델 모듈\n",
    "class PredictModel:\n",
    "    def __init__(self, category, model_name, proprocess):\n",
    "        \n",
    "        self.MAX_SEQ_LEN = 15\n",
    "        self.category = category\n",
    "        \n",
    "        if self.category =='intent':\n",
    "            self.labels = {0: '기타', 1: '추천', 2: '후기', 3: '정보', 4: '예매', 5: '욕설'}\n",
    "            \n",
    "        elif self.category == 'emotion':\n",
    "            self.labels = {0: '무서움', 1: '슬픔', 2: '신남', 3: '없음', 4: '웃김', 5: '재미'}\n",
    "            \n",
    "        elif self.category == 'binary':\n",
    "            self.labels = {0: '긍정', 1: '부정', 2: '없음'}\n",
    "            \n",
    "        elif self.category == 'trend':\n",
    "            self.labels = {0: '없음', 1: '인기', 2: '최신'}\n",
    "            \n",
    "        elif self.category == 'ner':\n",
    "            self.MAX_SEQ_LEN = 40\n",
    "            self.labels = {1: 'O', 2: 'B_MOVIE', 3: 'B_ACT', 4: 'B_GEN', 5: 'B_NAT', 6: 'B_DIR', 7: 'B_DT', 8: 'B_RAT', 0: 'PAD'}\n",
    "            \n",
    "        else:\n",
    "            self.labels = {}\n",
    "\n",
    "        self.labels[len(self.labels)]=\"-\"\n",
    "        # 분류 모델 불러오기\n",
    "        self.model = load_model(model_name)\n",
    "        # 챗봇 Preprocess 객체\n",
    "        self.p = proprocess\n",
    "\n",
    "    # 클래스 예측\n",
    "    def predict_class(self, query):\n",
    "        # 형태소 분석\n",
    "        pos = self.p.pos(query)\n",
    "        \n",
    "        # 문장내 키워드 추출(불용어 제거)\n",
    "        keywords = self.p.get_keywords(pos, without_tag=True)\n",
    "        sequences = [self.p.get_wordidx_sequence(keywords)]\n",
    "\n",
    "        # 패딩처리\n",
    "        padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=self.MAX_SEQ_LEN, padding='post')\n",
    "        predict = self.model.predict(padded_seqs)\n",
    "        predict_class = tf.math.argmax(predict, axis=1)\n",
    "\n",
    "        return predict_class.numpy()[0]\n",
    "\n",
    "    # ner_전용\n",
    "    def predict_ner(self, query):\n",
    "        # 형태소 분석\n",
    "        pos = self.p.pos(query)\n",
    "\n",
    "        # 문장내 키워드 추출(불용어 제거)\n",
    "        keywords = self.p.get_keywords(pos, without_tag=True)\n",
    "        sequences = [self.p.get_wordidx_sequence(keywords)]\n",
    "\n",
    "        # 패딩처리\n",
    "        max_len = 40\n",
    "        padded_seqs = preprocessing.sequence.pad_sequences(sequences, padding=\"post\", value=0,\n",
    "                                                           maxlen=max_len)\n",
    "        predict = self.model.predict(np.array([padded_seqs[0]]))\n",
    "        predict_class = tf.math.argmax(predict, axis=-1)\n",
    "        tags = [self.labels[i] for i in predict_class.numpy()[0]]\n",
    "        return list(zip(keywords, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# GPU에서 실행\n",
    "import tensorflow as tf\n",
    "with tf.device('/:GPU0'):\n",
    "        p = Preprocess(word2index_dic='c:/2nd_project/Data/chatbot_dict.bin',\n",
    "                        userdic = 'c:/2nd_project/Data/ner_data/new_user_dic_10.txt')\n",
    "\n",
    "        intent = PredictModel(category='intent', model_name='c:/2nd_project/Model/intent_model/intent_uso_model_0811_a_ep_best(5).h5', proprocess=p)\n",
    "        emotion = PredictModel(category='emotion', model_name='c:/2nd_project/Model/emotion_model/question_emotion_model.h5', proprocess=p)\n",
    "        binary = PredictModel(category='binary', model_name='c:/2nd_project/Model/binary_model/question_emotion_binary_model.h5', proprocess=p)\n",
    "        trend = PredictModel(category='trend', model_name='c:/2nd_project/Model/trend_model/question_trend_model.h5', proprocess=p)\n",
    "        ner = PredictModel(category='ner', model_name='c:/2nd_project/Model/ner_model/ner_model_0817_a.h5', proprocess=p)\n",
    "\n",
    "        def ner_tag_sep(lsts):\n",
    "                ner_movie = []\n",
    "                ner_act = []\n",
    "                ner_gen = []\n",
    "                ner_nat = []\n",
    "                ner_dir = []\n",
    "                ner_dt = []\n",
    "                ner_rat = []\n",
    "\n",
    "                for lst in lsts:\n",
    "                        if lst[1] == 'B_MOVIE':\n",
    "                                ner_movie.append(lst[0])\n",
    "                        elif lst[1] == 'B_ACT':\n",
    "                                ner_act.append(lst[0])\n",
    "                        elif lst[1] == 'B_GEN':\n",
    "                                ner_gen.append(lst[0])\n",
    "                        elif lst[1] == 'B_NAT':\n",
    "                                ner_nat.append(lst[0])\n",
    "                        elif lst[1] == 'B_DIR':\n",
    "                                ner_dir.append(lst[0])\n",
    "                        elif lst[1] == 'B_DT':\n",
    "                                ner_dt.append(lst[0])\n",
    "                        elif lst[1] == 'B_RAT':\n",
    "                                ner_rat.append(lst[0])\n",
    "\n",
    "                        ner_movie = list(set(ner_movie))\n",
    "                        ner_act = list(set(ner_act))\n",
    "                        ner_gen = list(set(ner_gen))\n",
    "                        ner_nat = list(set(ner_nat))\n",
    "                        ner_dir = list(set(ner_dir))\n",
    "                        ner_dt = list(set(ner_dt))\n",
    "                        ner_rat = list(set(ner_rat))\n",
    "\n",
    "                return ner_movie, ner_act, ner_gen, ner_nat, ner_dir, ner_dt, ner_rat\n",
    "\n",
    "        def predict_keyword(text):\n",
    "        \n",
    "                intent_pred = intent.predict_class(text)\n",
    "                emotion_pred = emotion.predict_class(text)\n",
    "                binary_pred = binary.predict_class(text)\n",
    "                trend_pred = trend.predict_class(text)\n",
    "                ner_pred = ner.predict_ner(text)\n",
    "                \n",
    "                intent_label = intent.labels[intent_pred]\n",
    "                emotion_label = emotion.labels[emotion_pred]\n",
    "                binary_label = binary.labels[binary_pred]\n",
    "                trend_label = trend.labels[trend_pred]\n",
    "                ner_label = ner_tag_sep(ner_pred)\n",
    "\n",
    "                return intent_label, emotion_label, binary_label, trend_label, ner_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6개월 전 날짜: 2023-02-18\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# 현재 날짜 가져오기\n",
    "now = datetime.now()\n",
    "\n",
    "# 6개월 전 날짜 계산\n",
    "six_months_ago = now - relativedelta(months=6)\n",
    "\n",
    "# 결과를 원하는 형식으로 포맷팅\n",
    "recent = six_months_ago.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "print(\"6개월 전 날짜:\", recent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FindAnswer:\n",
    "    def __init__(self, db):\n",
    "        self.db = db\n",
    "\n",
    "    def recent_day():\n",
    "        now = datetime.now()\n",
    "        six_months_ago = now - relativedelta(months=6)\n",
    "        recent = six_months_ago.strftime(\"%Y-%m-%d\")\n",
    "        return recent\n",
    "\n",
    "    def intent_query(lsts):\n",
    "        ## 의도\n",
    "        if lsts[0] == \"추천\":\n",
    "            sql_intent = 'order by rand() limit 1;'    # 랜덤으로 하나 추천\n",
    "        elif ((lsts[0] == '후기') | (lsts[0] == '정보')):\n",
    "            sql_intent = ''    # 해당 조건 검색\n",
    "        else:\n",
    "            print('의도 없음')\n",
    "        return sql_intent\n",
    "\n",
    "    def emotion_query(lsts):\n",
    "        ## 감정(긍/부정) > DB keyword(무서움/슬픔/신남/웃김/재미/null)\n",
    "            #   SELECT * FROM chat_movie WHERE keyword = 'lsts[1]'\n",
    "        if lsts[1] != \"없음\":   # emotion이 유효할때(무서움/슬픔/신남/웃김/재미)\n",
    "            print('감정있음')\n",
    "            if lsts[2] != \"부정\":\n",
    "                print('그 감정 그대로') # (무서움/슬픔/신남/웃김/재미 + 없음)\n",
    "                sql_keyword = f\"keyword = '{lsts[1]}'\"\n",
    "            else:\n",
    "                print('그 감정 반대')\n",
    "                sql_keyword = f\"keyword != '{lsts[1]}'\"\n",
    "        else:   # emotion이 없음 일때\n",
    "            print('랜덤')\n",
    "        return sql_keyword\n",
    "\n",
    "    def trend_query(lsts):\n",
    "        ## 트렌드\n",
    "        if lsts[3] == '최신':\n",
    "            sql_trend = f\"opendate >= '{recent}'\" # 최신(6개월)\n",
    "            # sql = sql + \" people>=1000000 order by opendate DESC limit 1\"\n",
    "        elif lsts[3] == '인기':\n",
    "            sql_trend = \"people >= 5000000\"\n",
    "            # sql = sql + \" people>=5000000 order by rand() limit 1\"\n",
    "        else:\n",
    "            sql_trend = \"people >= 1000000\"\n",
    "            # sql = sql + \" people>=1000000 order by rand() limit 1\"\n",
    "        return sql_trend\n",
    "\n",
    "    def ner_query(lst):\n",
    "        sql_lst = []\n",
    "\n",
    "        # 배우 포함\n",
    "        if lst[1] != []:\n",
    "            for act in lst[1]:\n",
    "                sql = f\"actors like '%{act}%'\"\n",
    "                sql_lst.append(sql)\n",
    "                \n",
    "        # 장르 포함\n",
    "        if lst[2] != []:\n",
    "            for gen in lst[2]:\n",
    "                sql = f\"genre like '%{gen}%'\"\n",
    "                sql_lst.append(sql)\n",
    "        \n",
    "        # 국적 - 대표국적으로 구분\n",
    "        if lst[3] != []:\n",
    "            한국 = ['대한민국','우리나라','국내']\n",
    "            외국 = ['해외','외국']\n",
    "            for nat in lst[3]:\n",
    "                if nat in 한국:\n",
    "                    sql = \"repnations like '한국'\"\n",
    "                elif nat in 외국:\n",
    "                    sql = \"repnations not like '한국'\"\n",
    "                else:\n",
    "                    sql = f\"repnations like '{nat}'\"\n",
    "                sql_lst.append(sql)\n",
    "        \n",
    "        # 감독 포함\n",
    "        if lst[4] != []:\n",
    "            for direc in lst[4]:\n",
    "                sql = f\"director like '%{direc}%'\"\n",
    "                sql_lst.append(sql)\n",
    "                \n",
    "        if len(sql_lst)==0:\n",
    "            sql =''\n",
    "        else:\n",
    "            sql = ' and '.join(sql_lst)\n",
    "        return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def recent_day():\n",
    "#     now = datetime.now()\n",
    "#     six_months_ago = now - relativedelta(months=6)\n",
    "#     recent = six_months_ago.strftime(\"%Y-%m-%d\")\n",
    "#     return recent\n",
    "\n",
    "# recent = recent_day()\n",
    "\n",
    "# def sql_query(lsts):\n",
    "#     sql = 'select * from chat_movie WHERE'\n",
    "#     # sql_end = ''\n",
    "#     # sql_keyword = ''\n",
    "#     # sql_trend = ''\n",
    "\n",
    "#     ## 의도\n",
    "#     if lsts[0] == \"추천\":\n",
    "#         sql_end = 'order by rand() limit 1;'    # 랜덤으로 하나 추천\n",
    "#     elif ((lsts[0] == '후기') | (lsts[0] == '정보')):\n",
    "#         sql_end = ''    # 해당 조건 검색\n",
    "#     else:\n",
    "#         print('의도 없음')\n",
    "\n",
    "        \n",
    "#     ## 감정(긍/부정) > DB keyword(무서움/슬픔/신남/웃김/재미/null)\n",
    "#         #   SELECT * FROM chat_movie WHERE keyword = 'lsts[1]'\n",
    "#     if lsts[1] != \"없음\":   # emotion이 유효할때(무서움/슬픔/신남/웃김/재미)\n",
    "#         print('감정있음')\n",
    "#         if lsts[2] != \"부정\":\n",
    "#             print('그 감정 그대로') # (무서움/슬픔/신남/웃김/재미 + 없음)\n",
    "#             sql_keyword = f\"keyword = '{lsts[1]}'\"\n",
    "#         else:\n",
    "#             print('그 감정 반대')\n",
    "#             sql_keyword = f\"keyword != '{lsts[1]}'\"\n",
    "#     else:   # emotion이 없음 일때\n",
    "#         print('랜덤')\n",
    "\n",
    "#     ## 트렌드\n",
    "#     if lsts[3] == '최신':\n",
    "#         sql_trend = f\"opendate >= '{recent}'\" # 최신(6개월)\n",
    "#         # sql = sql + \" people>=1000000 order by opendate DESC limit 1\"\n",
    "#     elif lsts[3] == '인기':\n",
    "#         sql_trend = \"people >= 5000000\"\n",
    "#         # sql = sql + \" people>=5000000 order by rand() limit 1\"\n",
    "#     else:\n",
    "#         sql_trend = \"people >= 1000000\"\n",
    "#         # sql = sql + \" people>=1000000 order by rand() limit 1\"\n",
    "    \n",
    "#     sql = f\"{sql} ({sql_keyword} and {sql_trend}) {sql_end}\"\n",
    "#     return sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 129ms/step\n",
      "1. 의도 : 추천\n",
      "2. 감정 : 슬픔\n",
      "3. 긍부정 : 긍정\n",
      "4. 트렌드 : 인기\n",
      "5. 개체명\n",
      "\t영화명 : []\n",
      "\t배우 : ['박서준']\n",
      "\t장르 : []\n",
      "\t국가 : []\n",
      "\t감독 : ['봉준호']\n",
      "\t시간 : []\n",
      "\t등급 : []\n"
     ]
    }
   ],
   "source": [
    "# # text = '기생충 영화 드림 기생충 감독 봉준호 내가 좋아하는 배우는 황정민 박서준 고소영 우리나라 호러 장르는 액션  미국 오늘은 8월 전체관람가인 영화 추천 12시 안해주면 화날꺼같아'\n",
    "# text = '천만 넘은 봉준호 감독에 박서준 나온 재밌는 영화 없어서 슬픈데 영화 추천좀'\n",
    "\n",
    "# lsts = predict_keyword(text)\n",
    "\n",
    "# print('1. 의도 :', lsts[0])\n",
    "# print('2. 감정 :', lsts[1])\n",
    "# print('3. 긍부정 :', lsts[2])\n",
    "# print('4. 트렌드 :', lsts[3])\n",
    "# print('5. 개체명\\n\\t영화명 : {}\\n\\t배우 : {}\\n\\t장르 : {}\\n\\t국가 : {}\\n\\t감독 : {}\\n\\t시간 : {}\\n\\t등급 : {}'\n",
    "# .format(lsts[4][0], lsts[4][1], lsts[4][2], lsts[4][3], lsts[4][4], lsts[4][5], lsts[4][6]))\n",
    "\n",
    "# # sql = sql_querty(lst)\n",
    "# # print(sql)\n",
    "# # db.select_all(sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # intent = lsts[0]\n",
    "# # emotion = lsts[1] / 6\n",
    "# # binary = lsts[2]  / 3\n",
    "# # trend = lsts[3]   / 3\n",
    "# # movie = lsts[4][0]\n",
    "# # actor = lsts[4][1]\n",
    "# # genre = lsts[4][2]\n",
    "# # nation = lsts[4][3]\n",
    "# # director = lsts[4][4]\n",
    "# # date = lsts[4][5]\n",
    "# # rating = lsts[4][6]\n",
    "\n",
    "# # 아무 영화 추천(lsts[0]으로만)\n",
    "# # (감정) 영화 추천(lsts[1], lsts[2])\n",
    "# # (트랜드) 영화 추천(lsts[3])\n",
    "# # 영화이름으로 추천 / 배우명으로 추천 / 장르별 추천 / 국가별 추천 / 감독명으로 추천 / 등급별 추천\n",
    "\n",
    "# # ('추천', '슬픔', '긍정', '인기', ([], ['박서준'], [], [], ['봉준호'], [], []))\n",
    "\n",
    "#         # if self.category =='intent':\n",
    "#         #     self.labels = {0: '기타', 1: '추천', 2: '후기', 3: '정보', 4: '예매', 5: '욕설'}\n",
    "            \n",
    "#         # elif self.category == 'emotion':\n",
    "#         #     self.labels = {0: '무서움', 1: '슬픔', 2: '신남', 3: '없음', 4: '웃김', 5: '재미'}\n",
    "            \n",
    "#         # elif self.category == 'binary':\n",
    "#         #     self.labels = {0: '긍정', 1: '부정', 2: '없음'}\n",
    "            \n",
    "#         # elif self.category == 'trend':\n",
    "#         #     self.labels = {0: '없음', 1: '인기', 2: '최신'}\n",
    "            \n",
    "#         # elif self.category == 'ner':\n",
    "#         #     self.MAX_SEQ_LEN = 40\n",
    "#         #     self.labels = {1: 'O', 2: 'B_MOVIE', 3: 'B_ACT', 4: 'B_GEN', 5: 'B_NAT', 6: 'B_DIR', 7: 'B_DT', 8: 'B_RAT', 0: 'PAD'}\n",
    "\n",
    "# def sql_querty(lsts):\n",
    "#     sql = 'select * from chat_movie'\n",
    "\n",
    "#     if lsts[0] == \"추천\":\n",
    "#         if lsts[2] == \"긍정\":\n",
    "#             sql_q = \" keyword like \"\n",
    "#         elif lsts[2] == '부정':\n",
    "#             sql_q = \" keyword not like \"\n",
    "#         else:\n",
    "#             sql_q = \" keyword not like \"\n",
    "        \n",
    "#         if lsts[1] != \"없음\":\n",
    "#             sql = sql + \" where\" + sql_q + f\"'%{lst[1]}%'\" +\" and keyword !='null' and\" \n",
    "#         else:\n",
    "#             sql = sql + \" where\"\n",
    "            \n",
    "#         if lsts[3] == '최신':\n",
    "#             sql = sql + \" people>=1000000 order by opendate DESC limit 1\"\n",
    "#         elif lsts[3] == '인기':\n",
    "#             sql = sql + \" people>=5000000 order by rand() limit 1\"\n",
    "#         else:\n",
    "#             sql = sql + \" people>=1000000 order by rand() limit 1\"\n",
    "    \n",
    "#     return sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 답변"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intent = lsts[0]\n",
    "# emotion = lsts[1]\n",
    "# binary = lsts[2]\n",
    "# trend = lsts[3]\n",
    "# movie = lsts[4][0]\n",
    "# actor = lsts[4][1]\n",
    "# genre = lsts[4][2]\n",
    "# nation = lsts[4][3]\n",
    "# director = lsts[4][4]\n",
    "# date = lsts[4][5]\n",
    "# rating = lsts[4][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 220ms/step\n",
      "1. 의도 : 추천\n",
      "2. 감정 : 슬픔\n",
      "3. 긍부정 : 긍정\n",
      "4. 트렌드 : 인기\n",
      "5. 개체명\n",
      "\t영화명 : []\n",
      "\t배우 : ['박서준']\n",
      "\t장르 : []\n",
      "\t국가 : []\n",
      "\t감독 : []\n",
      "\t시간 : []\n",
      "\t등급 : []\n",
      "('추천', '슬픔', '긍정', '인기', ([], ['박서준'], [], [], [], [], []))\n",
      "감정있음\n",
      "그 감정 그대로\n",
      "select * from chat_movie WHERE (keyword = '슬픔' and people >= 5000000) order by rand() limit 1;\n",
      "[{'title': '해운대', 'opendate': datetime.datetime(2009, 7, 22, 0, 0), 'people': '11325117', 'grade': '12세이상관람가', 'genre': '액션,드라마,어드벤처', 'repnation': '한국', 'nations': '한국', 'Production': '(주)제이케이필름', 'distributor': 'CJ ENM', 'director': '윤제균', 'actors': '설경구,하지원,박중훈,엄정화,이민기,강대규,김원영,김유빈,신정원,성유경,박재홍,황인준,나승현,김인호,근휘,김재경,장원준,임동우,김정곤,정종원,이지애,이태영,최재섭,장명갑,지대한,천보근,박영수,염동헌,주민하,강예원,손희순,변상윤', 'story': '2004년 역사상 유례없는 최대의 사상자를 내며 전세계에 엄청난 충격을 안겨준 인도네시아 쓰나미. 당시 인도양에 원양어선을 타고 나갔던 해운대 토박이 만식은 예기치 못한 쓰나미에 휩쓸리게 되고, 단 한 순간의 실수로 그가 믿고 의지했던 연희 아버지를 잃고 만다. 이 사고 때문에 그는 연희를 좋아하면서도 자신의 마음을 숨길 수 밖에 없다. 그러던 어느 날, 만식은 오랫동안 가슴 속에 담아두었던 자신의 마음을 전하기로 결심하고 연희를 위해 멋진 프로포즈를 준비한다. 만식의 동생이자 해운대 해양구조대원인 형식은 해양 순찰을 돌던 중 바다 한 가운데에 빠져 허우적대던 희미를 발견하고 우여곡절 끝에 그녀를 구출한다. 자신을 구해준 순수 청년 형식에게 첫 눈에 반한 희미. 그녀는 형식을 향해 저돌적인 애정공세를 펼치고, 형식 역시 그런 그녀가 싫지만은 않다. 국제해양연구소의 지질학자 김휘는 해운대 일대 지각의 움직임이 심상치 않음을 감지해 해운대를 찾는다. 그는 그 곳에서 7년 전 이혼한 아내 유진과 딸 지민을 우연히 만나지만 지민이 자신의 존재를 모른다는 사실에 복잡한 감정을 느낀다. 일에 성공한 커리어우먼 유진은 바쁜 일로 인해 어린 지민을 혼자 두기 일쑤다. 한편, 그 순간에도 바다의 상황은 시시각각 변해가고 마침내 김휘의 예상대로 일본 대마도가 내려 앉으면서 초대형 쓰나미가 생성된다. 한여름 더위를 식히고 있는 수백만의 휴가철 인파와 평화로운 일상을 보내고 있는 부산 시민들, 그리고 저마다의 사연을 가진 이들에게 초대형 쓰나미가 시속 800km의 빠른 속도로 밀려오는데…', 'keyword': '슬픔'}]\n",
      "해운대\n"
     ]
    }
   ],
   "source": [
    "# text = '기생충 영화 드림 기생충 감독 봉준호 내가 좋아하는 배우는 황정민 박서준 고소영 우리나라 호러 장르는 액션  미국 오늘은 8월 전체관람가인 영화 추천 12시 안해주면 화날꺼같아'\n",
    "query = '인기있는 박서준 나온 무서운 영화 없어서 슬퍼 추천좀'\n",
    "\n",
    "lsts = predict_keyword(query)\n",
    "\n",
    "print('1. 의도 :', lsts[0])\n",
    "print('2. 감정 :', lsts[1])\n",
    "print('3. 긍부정 :', lsts[2])\n",
    "print('4. 트렌드 :', lsts[3])\n",
    "print('5. 개체명\\n\\t영화명 : {}\\n\\t배우 : {}\\n\\t장르 : {}\\n\\t국가 : {}\\n\\t감독 : {}\\n\\t시간 : {}\\n\\t등급 : {}'\n",
    ".format(lsts[4][0], lsts[4][1], lsts[4][2], lsts[4][3], lsts[4][4], lsts[4][5], lsts[4][6]))\n",
    "\n",
    "print(lsts)\n",
    "\n",
    "sql = sql_query(lsts)\n",
    "print(sql)\n",
    "\n",
    "movie_data = db.select_all(sql)\n",
    "print(movie_data)\n",
    "\n",
    "recomand_movie = movie_data[0]['title']\n",
    "print(recomand_movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 의도\n",
    "answer_i = ''\n",
    "if lsts[0] == '기타':\n",
    "    answer_i = '의도를 잘 모르겠어요.'\n",
    "elif lsts[0] == '추천':\n",
    "    answer_i = '을(를) 추천드려요. :)'\n",
    "elif lsts[0] == '후기':\n",
    "    answer_i = '은(는) 후기가 있습니다.'\n",
    "elif lsts[0] == '정보':\n",
    "    answer_i = '은(는) 정보가 있습니다.'\n",
    "elif lsts[0] == '예매':\n",
    "    answer_i = '예매 되었습니다!'\n",
    "elif lsts[0] == '욕설':\n",
    "    answer_i = '욕설은 나빠요 :('\n",
    "else:\n",
    "    answer_i = 'intent error'\n",
    "\n",
    "# 감정\n",
    "answer = ''\n",
    "if lsts[1] == '무서움':\n",
    "    if lsts[2] == '긍정':\n",
    "        answer_e = '무서운 영화인'\n",
    "    else:\n",
    "        answer_e = '무섭지 않은 영화인'\n",
    "elif lsts[1] == '슬픔':\n",
    "    if lsts[2] == '긍정':\n",
    "        answer_e = '슬픈 영화인'\n",
    "    else:\n",
    "        answer_e = '슬프지 않은 영화인'\n",
    "elif lsts[1] == '신남':\n",
    "    if lsts[2] == '긍정':\n",
    "        answer_e = '신나는 영화인'\n",
    "    else:\n",
    "        answer_e = '신나지 않은 영화인'\n",
    "elif lsts[1] == '없음':\n",
    "    answer_e = ''\n",
    "elif lsts[1] == '웃김':\n",
    "    if lsts[2] == '긍정':\n",
    "        answer_e = '웃긴 영화인'\n",
    "    else:\n",
    "        answer_e = '웃기지 않은 영화인'\n",
    "elif lsts[1] == '재미':\n",
    "    if lsts[2] == '긍정':\n",
    "        answer_e = '재미있는 영화인'\n",
    "    else:\n",
    "        answer_e = '재미없는 영화인'\n",
    "else:\n",
    "    answer_e = 'emotion error'\n",
    "\n",
    "# 트렌드\n",
    "if lsts[3] == '없음':\n",
    "    answer_t = ''\n",
    "elif lsts[3] == '인기':\n",
    "    answer_t = '인기 있는'\n",
    "elif lsts[3] == '최신':\n",
    "    answer_t = '최근'\n",
    "else:\n",
    "    answer_t = 'tred error'\n",
    "\n",
    "# 개체명\n",
    "# movie = lsts[4][0]\n",
    "# if len(movie) > 0:\n",
    "    \n",
    "# actor = lsts[4][1]\n",
    "# genre = lsts[4][2]\n",
    "# nation = lsts[4][3]\n",
    "# director = lsts[4][4]\n",
    "# date = lsts[4][5]\n",
    "# rating = lsts[4][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인기 있는 슬픈 영화인 '미션임파서블:고스트프로토콜'을(를) 추천드려요. :)\n"
     ]
    }
   ],
   "source": [
    "answer = f\"{answer_t} {answer_e} '{recomand_movie}'{answer_i}\"\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
