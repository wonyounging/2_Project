{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 임포트\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>정말요 어떤 내용이래요</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>애니메이션이면 개봉하면 저도 꼭 봐야겠어요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>그거 말고 추천작은요</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       text  label\n",
       "6              정말요 어떤 내용이래요      3\n",
       "12  애니메이션이면 개봉하면 저도 꼭 봐야겠어요      1\n",
       "43              그거 말고 추천작은요      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = pd.read_csv('c:/2nd_project/Data/talk_data/영화주제 대화 말뭉치 라벨링.csv')\n",
    "corpus_df = corpus_df[corpus_df['label'] != 0]\n",
    "corpus_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = \"c:/2nd_project/Data/talk_data/영화주제 대화 말뭉치 라벨링.csv\"\n",
    "data = pd.read_csv(train_file, delimiter=',')\n",
    "queries = data['text'].tolist()\n",
    "intents = data['label'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Preprocess2 import Preprocess2\n",
    "p = Preprocess2(word2index_dic='c:/2nd_project/Data/chatbot_dict_talk.bin',\n",
    "               userdic = 'c:/2nd_project/Data/user_dic.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = []\n",
    "for sentence in queries:\n",
    "    sentence = str(sentence)\n",
    "    pos = p.pos(sentence)\n",
    "    keywords = p.get_keywords(pos, without_tag=True)\n",
    "    seq = p.get_wordidx_sequence(keywords)\n",
    "    sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GlobalParams import MAX_SEQ_LEN\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  19,  456,    2, ...,    0,    0,    0],\n",
       "       [6713,  575, 2835, ...,    0,    0,    0],\n",
       "       [ 117,  887, 1507, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [ 185,   28,  317, ...,    0,    0,    0],\n",
       "       [ 185, 3471,  317, ...,    0,    0,    0],\n",
       "       [1173,   28,   85, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = corpus_df[['text']].astype(str)\n",
    "X = padded_seqs\n",
    "y = corpus_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 4, 4, 4], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_label = encoder.fit_transform(y)\n",
    "y_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(padded_seqs, intents, stratify=intents, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X, y_label, stratify=y_label, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    55606\n",
       "6     1272\n",
       "1     1132\n",
       "3      910\n",
       "4      191\n",
       "2      147\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "dropout_prob = 0.5\n",
    "EMB_SIZE = 128\n",
    "EPOCH = 5\n",
    "VOCAB_SIZE = len(p.word_index) + 1 # 전체 단어수 (패딩 0 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(20)\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(None, 15), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 15)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 15, 128)      1923968     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 15, 128)      0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 15, 128)      49280       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 15, 128)      65664       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 15, 128)      82048       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['conv1d[0][0]']                 \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 128)         0           ['conv1d_1[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Global  (None, 128)         0           ['conv1d_2[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 384)          0           ['global_max_pooling1d[0][0]',   \n",
      "                                                                  'global_max_pooling1d_1[0][0]', \n",
      "                                                                  'global_max_pooling1d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          49280       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 128)          16512       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          16512       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " logits (Dense)                 (None, 5)            645         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 5)            30          ['logits[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,203,939\n",
      "Trainable params: 2,203,939\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print(\"*\"*50)\n",
    "# print(padded_seqs)\n",
    "# print(padded_seqs.shape)\n",
    "# print('*'*50)\n",
    "# CNN 모델 정의\n",
    "input_layer = Input(shape=(MAX_SEQ_LEN,))\n",
    "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_SEQ_LEN)(input_layer)\n",
    "dropout_emb = Dropout(rate = dropout_prob)(embedding_layer)\n",
    "\n",
    "conv1 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=3,\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool1 = GlobalMaxPool1D()(conv1)\n",
    "\n",
    "conv2 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=4,\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "\n",
    "pool2 = GlobalMaxPool1D()(conv2)\n",
    "conv3 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=5,\n",
    "    padding='same',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool3 = GlobalMaxPool1D()(conv3)\n",
    "\n",
    "# 3,4,5gram 이후 합치기\n",
    "concat = concatenate([pool1, pool2, pool3])\n",
    "\n",
    "hidden1 = Dense(128, activation=tf.nn.relu)(concat)\n",
    "hidden2 = Dense(128, activation=tf.nn.relu)(hidden1)\n",
    "hidden3 = Dense(128, activation=tf.nn.relu)(hidden2)\n",
    "\n",
    "dropout_hidden = Dropout(rate=dropout_prob)(hidden3)\n",
    "logits = Dense(5, name='logits')(dropout_hidden)\n",
    "predictions = Dense(5, activation=tf.nn.softmax)(logits)\n",
    "\n",
    "# 모델 생성\n",
    "model = Model(inputs=input_layer, outputs=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2963/2963 [==============================] - 33s 11ms/step - loss: nan - accuracy: 0.9382 - val_loss: nan - val_accuracy: 0.9384\n",
      "Epoch 2/5\n",
      "2963/2963 [==============================] - 31s 10ms/step - loss: nan - accuracy: 0.9384 - val_loss: nan - val_accuracy: 0.9384\n",
      "Epoch 3/5\n",
      "2963/2963 [==============================] - 31s 10ms/step - loss: nan - accuracy: 0.9384 - val_loss: nan - val_accuracy: 0.9384\n",
      "Epoch 4/5\n",
      "2963/2963 [==============================] - 31s 10ms/step - loss: nan - accuracy: 0.9384 - val_loss: nan - val_accuracy: 0.9384\n",
      "Epoch 5/5\n",
      "2963/2963 [==============================] - 31s 10ms/step - loss: nan - accuracy: 0.9384 - val_loss: nan - val_accuracy: 0.9384\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH, verbose=1)\n",
    "\n",
    "model.save('c:/2nd_project/Model/intent_model_0808_b.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras import preprocessing\n",
    "\n",
    "# 의도 분류 모델 모듈\n",
    "class StoryModel:\n",
    "    def __init__(self, model_name, proprocess):\n",
    "        # intent 레이블\n",
    "        # self.labels = dict(zip(range(0,12),encoder.classes_.tolist()))\n",
    "        self.labels = {0: '추천',\n",
    "                        1: '후기',\n",
    "                        2: '정보',\n",
    "                        3: '예매',\n",
    "                        4: '욕설',\n",
    "                        }\n",
    "        # intent 분류 모델 불러오기\n",
    "        self.model = load_model(model_name)\n",
    "        # 챗봇 Preprocess 객체\n",
    "        self.p = proprocess\n",
    "\n",
    "    # 의도 클래스 예측\n",
    "    def predict_class(self, query):\n",
    "        # 형태소 분석\n",
    "        pos = self.p.pos(query)\n",
    "\n",
    "        # 문장내 키워드 추출(불용어 제거)\n",
    "        keywords = self.p.get_keywords(pos, without_tag=True)\n",
    "        sequences = [self.p.get_wordidx_sequence(keywords)]\n",
    "\n",
    "        # 패딩처리\n",
    "        padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')\n",
    "        predict = self.model.predict(padded_seqs)\n",
    "        predict_class = tf.math.argmax(predict, axis=1)\n",
    "\n",
    "        return predict_class.numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "오늘 영화 예매 해줘\n",
      "의도 예측 클래스 :  0\n",
      "의도 예측 레이블 :  추천\n"
     ]
    }
   ],
   "source": [
    "from Preprocess2 import Preprocess2\n",
    "p = Preprocess2(word2index_dic='c:/2nd_project/Data/chatbot_dict_talk.bin',\n",
    "               userdic = 'c:/2nd_project/Data/user_dic.txt')\n",
    "\n",
    "intent = StoryModel(model_name='c:/2nd_project/Model/intent_model_0808_b.h5', proprocess=p)\n",
    "\n",
    "items=[\"오늘 영화 예매 해줘\"]\n",
    "\n",
    "for item in items:\n",
    "\n",
    "    predict = intent.predict_class(item)\n",
    "\n",
    "    predict_label = intent.labels[predict]\n",
    "\n",
    "    print(item)\n",
    "\n",
    "    print(\"의도 예측 클래스 : \", predict)\n",
    "\n",
    "    print(\"의도 예측 레이블 : \", predict_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
